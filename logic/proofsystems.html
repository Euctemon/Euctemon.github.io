<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><title>Proof systems</title><link rel="icon" href="styles/favicon.ico"/><link rel="stylesheet" href="../styles/styles.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.27/dist/katex.min.css" integrity="sha384-Pu5+C18nP5dwykLJOhd2U4Xen7rjScHN/qusop27hdd2drI+lL5KvX7YntvT8yew" crossorigin="anonymous"/><script src="https://cdn.jsdelivr.net/npm/katex@0.16.27/dist/katex.min.js" defer="defer" crossorigin="anonymous" integrity="sha384-2B8pfmZZ6JlVoScJm/5hQfNS2TI/6hPqDZInzzPc8oHpN5SgeNOf4LzREO6p5YtZ"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.27/dist/contrib/auto-render.min.js" defer="defer" crossorigin="anonymous" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" onload="renderMathInElement(document.body);"></script><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="description" content="A beautiful site built with Tyxml"/></head><body><div class="content-flex"><div class="content-body"><h1>Proof systems</h1><p>So far we know, at least theoretically, how to check whether a formula is satisfiable, true or even tautology. In reality the underlying model for a language might have a universe of an infinite size. This means we would need to check an infinite number of different assignment functions and you surely understand that such a process takes a while. Either we come up with some clever way of working with the model or we have to declare a defeat.</p><p>Now there is something interesting we can do. We can turn the formula checking upside down and instead look for a finite model in which a given formula is satisfiable. Finite models are models with finite universes which means we can simply try all possible assignment functions and interpretations to find out whether the formula is satisfiable. If there is no suitable interpretation and assignment, we use a larger universe. The nice things is that we can write a program which does this for us. Finite model theories deal exatcly with things like this and it is very useful branch of mathematicsfor computer scientists.</p><h3>Axiomatic systems</h3><p>Checking manually the validity of formulas by writing down truth tables for all assignment function is not what mathematicians commonly do. But what do they do? Instead of throwing assingment functions at formulas one by one, mathematicians write proofs. A proof is essentially a sequence of formulas. We start with the so called axioms and then use rules for constructing new formulas out of old ones, hoping that at the end we derive the formula we want to prove. The rules are commonly know as inference rules and together with set of axioms constitute an axiomatic system.</p><p>Logic has a long history. Using set of axioms and inference rules dates back to Euclid and his elements. Euclid called the axioms of geometry as postulates. The study of axiomatic systems can be said to begin with Frege and Hilbert. They were not only using logic for mathematics, but they were interested in the axiomatic systems itself. People started to wonder whether all mathematics can be reduced to symbol manipulation or whether we can find the perfect set of axioms for everything. These are a very challenging questions and Gödel gave a partial answer with his incompleteness theorem.</p><p>In this chapter we will be mainly concerned with the propositional logic \(\mathcal{L}_p\). This is a logic with no function and relation symbols, an alphabet with infinite number of variables \(P_0, P_1, \ldots\) and standard set of logical symbols. This is an almost empty language, yet it is very important one. Thanks to logical connectives and many variables we can still form complex formulas like \((P_1 \\lor P_3) \to (P_2 \land (P_1 \to (P_4 \to P_2)))\). What follows is a version of an axiomatic system for propositional logic Hilbert was using.</p><div class="list-descript">Axioms</div><ul><li>\(\mathfrak{a} \to (\mathfrak{b} \to \mathfrak{a})\)</li><li>\((\mathfrak{a} \to (\mathfrak{b} \to \mathfrak{c})) \to ((\mathfrak{a} \to \mathfrak{b}) \to (\mathfrak{a} \to \mathfrak{c}))\)</li><li>\(\mathfrak{a} \to (\mathfrak{b} \to \mathfrak{a} \land \mathfrak{b})\)</li><li>\(\mathfrak{a} \land \mathfrak{b} \to \mathfrak{a}\)</li><li>\(\mathfrak{a} \land \mathfrak{b} \to \mathfrak{b}\)</li><li>\(\mathfrak{a} \to (\mathfrak{b} \lor \mathfrak{a})\)</li><li>\(\mathfrak{b} \to (\mathfrak{b} \lor \mathfrak{a})\)</li><li>\((\mathfrak{a} \to \mathfrak{c}) \to (\mathfrak{b} \to \mathfrak{c}) \to (\mathfrak{a} \lor \mathfrak{b} \to \mathfrak{c})\)</li><li>\(\lnot \lnot \mathfrak{a} \to \mathfrak{a}\)</li></ul><div class="list-descript">Rules</div><ul><li>If we can prove \(\mathfrak{a}\) and \(\mathfrak{a} \to \(\mathfrak{b}\), we can prove \(\mathfrak{b}\).</li></ul><p>We see that Hilbert's axiomatic system has only one rule called Modus ponens. Philosophers use this implication rule not only in propositional logic and they call it Modul ponendo ponens. This can be translated as <i>method that by affirming, affirms</i>. The rules we use for producing new formulas out of the proven ones are called inference rules, because we infer new things from old ones. The axioms are often called <i>axiom schemas</i>. This is because \(\mathfrak{a}, \mathfrak{b}\) and \(\mathfrak{c}\) are not concrete formulas, but rather formula symbols. Formula symbol is not an official name as people just say formula, but it is good to note the distinction between formulas in axiomatic systems and concrete formulas in languages like \(P_1 \to P_2\). So how do we use such system? First we need a definition of what a proof is.</p><div class="definition"><b>Proof</b> is a sequence \(\Psi_0,\ldots,\Psi_n\) of formulas such that for every \(k &lt; n + 1\), either \(\Psi_k\) is a formula in context \(\Gamma\), an axiom schema or there are indices \(i_0,\ldots,i_l&lt; k\) such that \(\Psi_k\) follow from \(\Psi_{i_0}, \\ldots, \\Psi_{i_l}\) by some inference rule. We say that \(\Psi_n\) is the conclusion and the sequence \(\Psi_0,\ldots,\Psi_n\) with hypotheses in \(\Gamma\) is a proof of \(\Psi_n\). We write \(\Gamma \vdash \Psi\) if there exists a proof of \(\Psi\) given the context \(\Gamma\).</div><p>We notice that the definition features something called <i>context</i>. This is a set of formulas which we suppose are true in the context of a given proof. It is not always true that when it rains, we get wet. Maybe we are smart and bring our umbrella when it rains. But let's say we assume the first implication is true. Then if we go out and it rains, we can conclude that we get wet. It's all about the context. We should put the last definition to use and prove something. We start slowly.</p><div class="theorem">\(\large \varnothing \normalsize \vdash P_0 \to (P_1 \to P_0)\).</div><div class="proof"><ol><li>Instance of the first schema where the formulas \(\mathfrak{a}\) nad \(\mathfrak{b}\) are variables \(P_0\) and \(P_1\)</li></ol>\(\blacksquare\)</div><p>This is a reminder that we can use any concrete formula with our axioms and by definition variables \(P_0\) and \(P_1\) are formulas in any language. Using concrete formulas is fine, but the powerful thing logicians do is that they prove things about the <i>structure</i> of the axiomatic system. The idea is that if the proof structure is the same for every concrete formula, then why not just prove it abstractly.</p><div class="theorem">\(\{\mathfrak{a} \land \mathfrak{b}\} \vdash \mathfrak{b} \land \mathfrak{a}\).</div><div class="proof"><ol><li>Obtain \(\mathfrak{a}\) by modus ponens using the context and the fourth axiom schema.</li><li>Obtain \(\mathfrak{b}\) by modus ponens using context and the fifth axiom schema.</li><li>Obtain \(\mathfrak{a} \to (\mathfrak{b} \land \mathfrak{a})\) by modus ponens using \(\mathfrak{b}\) and the third axiom schema.</li><li>Obtain \(\mathfrak{b} \land \\mathfrak{b}\) by modus ponens using \(\mathfrak{a} \to (\mathfrak{b} \land \mathfrak{a})\) and \(\mathfrak{a}\).</li></ol><p>We see that we learned something about the conjugation symbol – it does not matter if we swap formulas. We could prove many more things. For example same thing is true for the disjunction symbol. You might know the DeMorgan laws. These laws are very important theorems about the structure of logical connectives and how they play together. Let's prove something interesting.</p><div class="theorem">\(\varnothing \vdash P \to P\).</div><div class="proof"><ol><li>Obtain \(P \to (P \to P)\) as an instance of the first axiom schema.</li><li>Obtain \(P \to ((P \to P) \to P)\) as an instance of the first axiom schema.</li><li>Obtain \((P \to ((P \to P) \to P)) \to ((P \to (P \to P)) \to (P \to P))\) as an instance of the second axiom schema.</li><li>Obtain \(\((P \to (P \to P)) \to P \to P) \) by modus ponens using 2 and 3.</li><li>Obtain \(P \to P \) by modus ponens using 4 and 1.</li></ol></div><p>Why isn't this an axiom? It seems useful to know it from the start. We <i>could</i> add \(P \to P\) to the axiom schema and nothing would break. But we strive to have a set of axioms such that this set is in some sense minimal. This means that no axiom in the set is provable using the other axioms. We end the introduction to axiomatic systems with the following theorem.</p><div class="theorem">Suppose \(\Gamma\) is a set of formulas. The set of formulas (set of consequences) provable from \(\Gamma\) is inductively generated by these rules<ul><li>If \(A \in \(\Gamma\)\), then \(\Gamma \vdash A\)</li><li>If \(A\) is an axiom schema, then \(\Gamma \vdash A\)</li><li>If \(\Gamma \vdash A\) and \(\Gamma \vdash A \to B\), then \(\Gamma \vdash B\)</li></ul></div><p>The proof of each statement follows almost directly from the definition of a proof. We only have to be little cautious with the last statement. This statement is only valid in axiomatic systems having the <i>modus ponens</i> rule. We will later see another proof system which is build a little differently.</p><div class="theorem">Fix a context \(\Gamma\) and a proposition \(P\). If \(\Gamma \cup\{P\} \vdash Q\) then \(\Gamma \vdash P \to Q\).</div><div class="proof"><p>We fix \(\Gamma\) and \(P\) and use the induction on the set of consequences of \(\Gamma \cup\{P\}\). This means that if \(Q\) is in the set of consequences, it has the form of one of the three cases mentioned earlier.</p></div><ol><li>\(Q \in \Gamma, P\)</li><li>\(Q\) as an axiom schema</li><li>There is proposition \(C\) such that \(\Gamma \cup\{P\} \vdash C\) and also \(\Gamma \cup\{P\} \vdash C \to Q\)</li></ol><p>We start with the first case. This is a tricky one. If \(P \in \Gamma\), we know that \(\Gamma \vdash P\). Using the first axiom schema we also know that \(\Gamma \vdash Q \to (P \to Q)\) as axioms follow from any context! The conclusion \(\Gamma \vdash Q \to P\) is obtained by modus ponens. What if \(Q\) is \(P\) itself? We need to prove that \(\Gamma \vdash P \to P\). Luckily we proved this already. The second case is easier. If \(Q\) is an axiom schema, we know that \(\Gamma \vdash Q\). We again use the first axiom schema to conclude \(\Gamma \vdash Q \to (P \to Q)\) and modus ponens to obtain the conclusion \(\Gamma \vdash P \to Q\).</p><p>From the structure of the set of proposition, we know that if \(Q\) is not an axiom schema or is not the element of \(\Gamma \cup\{P\}\), it had to be <i>constructed</i> using modus ponens. We therefore know there has to be a proposition \(C\) satisfying \(\Gamma \cup\{P\} \vdash C\) and also \(\Gamma \cup\{P\} \vdash C \to Q\). Now we finally use the induction. Thi means we can use the conclusion of the theorem for the proposition \(C\). We know that \(\Gamma \cup\{P\} \vdash C\) and thus conclude \(\Gamma \vdash P \to C\). In the same manner we conclude \(\Gamma \vdash P \to (C \to Q)\). We also have the second axiom schema at our disposal in the form \(\Gamma \vdash P \to (C \to Q) \to ((P \to C) \to (P \to Q))\). Again, we know we can prove this as axioms follow from any context. But now it suffices to use modus ponens two times and we are done.</p><h3>Theories</h3><p>When someone speaks about a theory of groups, or theory of lattices, they automatically assume one works with first order logic. Apart from using logical connectives, this logic has two quantifiers, the so-called existential \((\, \exists\,\)\) and universal \((\,\forall\,\)\) quantifier. We already know that including logical symbols in language is probably a good idea. Their universal interpretation enables us to write tautologies even though there might not be any tautologies in the set of atomic formulas. Why do we need quantifiers? A formula can be satisfiable, true or tautology. We know that tautology does not depend on the given model. But what happens when we fix a model? Now the formula might be satisfiable or true.</p><p>For a single variable in a formula the quantifiers are in correspondence with satisfiability and truth. Fix a language with no functions and only one relation \(r\) and interpret this language in the model with a universe of integers and less than relation. The formula \(\exists x,\: x &lt; 5\) is satisfiable because of number 3, but not true because of number 6. The numbers are the assignments themselves. Explicitly we have assignment functions \(v_1(x) = 3\) and \(v_2(x) = 6\). The situation becomes complicated for more than one variable. What about the atomic formula \(x &lt; y\)? It is not true, but it is satisfiable. This is fine, but rather coarse distinction. For integers we know that for a given number we can always pick a smaller number. Let's look at the formula \(\forall y,\exists x,\: x &lt; y\) and think about the assignment function \(v(x,y)\) for a bit. The function \(v\) assigns integers to the variables \(x\) and \(y\). Let's pretend we can split the assignment function \(v\) into two functions, \(v_x\) and \(v_y\). The function \(v_2\) can assign any number to \(y\), which we model by the universal assignment. The function \(v_1\) then must assign number smaller than \(v_2(y)\). By defining such assignments, we make the formula true.</p><p> The use of quantitiers is essential in mathematics. For example if we switch the quantifiers in the last formula as \(\exists y, \forall x,\: x &lt; y\), the formula is no longer true. Without quantifiers, we could only discern whether the formula is true or satisfiable. With quantifiers, we can see how much it is satisfiable. The formula \(\exists y, \exists x,\: x &lt; y\) being true means that we can find two numbers satisfying the inequality. On the other hand \(\forall y, \exists x,\: x &lt; y\) means we can allways find a smaller number \(x\) for any given number \(y\).</p></div></div></div><div class="left-right-nav"><a href="../logic/languages.html"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 3 30 30" width="35px" height="35px"><path d="M 19 9 L 13 15 L 19 21" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3px"></path></svg></a><a href="../blog.html">Blog</a><a href="../logic/completeness.html"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 3 30 30" width="35px" height="35px"><path d="M 12 9 L 18 15 L 12 21" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3px"></path></svg></a></div></body></html>
